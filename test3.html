<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Voice to Text WAV</title>
</head>
<body>
  <h2>ğŸ™ï¸ Say: "I refueled the car to 500 kilometers"</h2>
  <button onclick="record()">ğŸ™ï¸ Start Recording</button>
  <p id="output">Waiting...</p>

  <script>
    function record() {
      navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
        const audioContext = new AudioContext();
        const mediaStreamSource = audioContext.createMediaStreamSource(stream);
        const recorder = new Recorder(mediaStreamSource, { numChannels: 1 });

        recorder.record();
        document.getElementById("output").innerText = "Recording...";

        setTimeout(() => {
          recorder.stop();
          recorder.exportWAV(blob => {
            transcribeAudio(blob);
          });
        }, 8000); // ØªØ³Ø¬ÙŠÙ„ 8 Ø«ÙˆØ§Ù†ÙŠ
      });
    }

    function transcribeAudio(audioBlob) {
      const formData = new FormData();
      formData.append("file", audioBlob, "voice.wav");
      formData.append("model", "whisper-1");
      formData.append("language", "en");

      fetch("https://api.openai.com/v1/audio/transcriptions", {
        method: "POST",
        headers: {
          Authorization: "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"
        },
        body: formData
      })
      .then(res => res.json())
      .then(data => {
        document.getElementById("output").innerText = data.text || "âŒ No text returned.";
        console.log("Response:", data);
      })
      .catch(err => {
        document.getElementById("output").innerText = "âŒ Error during transcription.";
        console.error(err);
      });
    }
  </script>

  <!-- Ø¥Ø¶Ø§ÙØ© Ù…ÙƒØªØ¨Ø© ØªØ³Ø¬ÙŠÙ„ WAV -->
  <script src="https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs/recorder.js"></script>
</body>
</html>
