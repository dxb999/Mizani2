<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Voice to Text with Whisper (WAV)</title>
  <style>
    body { font-family: Arial; padding: 20px; }
    #output, #status { margin-top: 20px; padding: 10px; border-radius: 5px; }
    #output { background: #f0f8ff; }
    #status { background: #e8e8e8; font-weight: bold; }
    canvas { border: 1px solid #ccc; margin-top: 10px; }
  </style>
</head>
<body>
  <h2>ğŸ™ï¸ Say something like: "I refueled the car to 500 kilometers"</h2>
  <button onclick="record()">ğŸ™ï¸ Start Recording</button>
  <p id="status">Status: Idle</p>
  <p id="output">Waiting for speech...</p>
  <canvas id="levelMeter" width="300" height="30"></canvas>

  <!-- Ù…ÙƒØªØ¨Ø© ØªØ³Ø¬ÙŠÙ„ WAV -->
  <script src="https://cdn.jsdelivr.net/gh/mattdiamond/Recorderjs/recorder.js"></script>

  <script>
    let audioContext, recorder, analyser, dataArray, animationId;

    function record() {
      navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
        document.getElementById("status").innerText = "Status: ğŸ™ï¸ Microphone accessed successfully";

        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const source = audioContext.createMediaStreamSource(stream);

        // Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø¬Ù„
        recorder = new Recorder(source, { numChannels: 1 });
        recorder.record();

        // Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ­Ù„ÙŠÙ„ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª
        analyser = audioContext.createAnalyser();
        source.connect(analyser);
        analyser.fftSize = 256;
        const bufferLength = analyser.frequencyBinCount;
        dataArray = new Uint8Array(bufferLength);

        drawLevelMeter();

        document.getElementById("status").innerText = "Status: ğŸ”´ Recording...";
        document.getElementById("output").innerText = "Listening... Please speak clearly.";

        setTimeout(() => {
          recorder.stop();
          cancelAnimationFrame(animationId);
          document.getElementById("status").innerText = "Status: â³ Processing recording...";
          recorder.exportWAV(blob => {
            transcribeAudio(blob);
          });
        }, 8000); // ØªØ³Ø¬ÙŠÙ„ Ù„Ù…Ø¯Ø© 8 Ø«ÙˆØ§Ù†ÙŠ
      }).catch(err => {
        document.getElementById("status").innerText = "Status: âŒ Microphone access failed.";
        console.error("Mic error:", err);
      });
    }

    function drawLevelMeter() {
      const canvas = document.getElementById("levelMeter");
      const ctx = canvas.getContext("2d");

      function draw() {
        animationId = requestAnimationFrame(draw);
        analyser.getByteFrequencyData(dataArray);

        let sum = 0;
        for (let i = 0; i < dataArray.length; i++) {
          sum += dataArray[i];
        }
        let average = sum / dataArray.length;

        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.fillStyle = "#4caf50";
        ctx.fillRect(0, 0, average * 3, canvas.height);
      }

      draw();
    }

    function transcribeAudio(audioBlob) {
      const formData = new FormData();
      formData.append("file", audioBlob, "voice.wav");
      formData.append("model", "whisper-1");
      formData.append("language", "en");

      document.getElementById("status").innerText = "Status: ğŸ”„ Sending to OpenAI Whisper API...";

      fetch("https://api.openai.com/v1/audio/transcriptions", {
        method: "POST",
        headers: {
          Authorization: "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"  // ğŸ”‘ Ø¶Ø¹ Ù…ÙØªØ§Ø­Ùƒ Ù‡Ù†Ø§
        },
        body: formData
      })
      .then(res => res.json())
      .then(data => {
        if (data.text) {
          document.getElementById("output").innerText = "ğŸ“ Transcription: " + data.text;
          document.getElementById("status").innerText = "Status: âœ… Transcription successful";
        } else {
          document.getElementById("output").innerText = "âŒ No text was returned from the API.";
          document.getElementById("status").innerText = "Status: âš ï¸ API returned no transcription";
        }
      })
      .catch(err => {
        document.getElementById("output").innerText = "âŒ Error: " + err.message;
        document.getElementById("status").innerText = "Status: âŒ Failed to contact Whisper API";
        console.error("API error:", err);
      });
    }
  </script>
</body>
</html>
