<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Voice to Text (Whisper)</title>
</head>
<body>
  <h2>ğŸ¤ Say something in English (e.g. "Fuel is now 500 kilometers")</h2>
  <button onclick="record()">ğŸ™ï¸ Start Recording</button>
  <p id="output">Waiting...</p>

  <script>
    function record() {
      navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
        const recorder = new MediaRecorder(stream);
        const chunks = [];

        recorder.ondataavailable = e => chunks.push(e.data);
        recorder.onstop = () => {
          const audioBlob = new Blob(chunks, { type: "audio/webm" });
          transcribeAudio(audioBlob);
        };

        recorder.start();
        document.getElementById("output").innerText = "ğŸ™ï¸ Recording...";

        setTimeout(() => {
          recorder.stop();
          document.getElementById("output").innerText = "â³ Processing...";
        }, 10000);
      });
    }

    function transcribeAudio(audioBlob) {
      const formData = new FormData();
      formData.append("file", audioBlob, "voice.webm");
      formData.append("model", "whisper-1");
      formData.append("language", "en"); // English

      fetch("https://api.openai.com/v1/audio/transcriptions", {
        method: "POST",
        headers: {
          Authorization: "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" // Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ù…ÙØªØ§Ø­Ùƒ
        },
        body: formData
      })
      .then(res => res.json())
      .then(data => {
        document.getElementById("output").innerText = data.text || "âŒ No text returned.";
        console.log("FULL:", data);
      })
      .catch(err => {
        document.getElementById("output").innerText = "âŒ Error";
        console.error(err);
      });
    }
  </script>
</body>
</html>
